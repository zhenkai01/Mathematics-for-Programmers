{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87d91ccd-b998-464a-ad95-a6565184bc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[-0.6196, -1.4761, -0.8153],\n",
      "        [-1.1934,  1.2537,  2.6364]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.zeros(2, 3)\n",
    "b = torch.ones(2, 3)\n",
    "c = torch.randn(2, 3)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35c70b47-e01f-48aa-a34f-1a0f24a87cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 从 numpy 数组创建张量\n",
    "import numpy as np\n",
    "numpy_array = np.array([[1,2,3],[4,5,6]])\n",
    "tensor_from_numpy = torch.from_numpy(numpy_array)\n",
    "print(tensor_from_numpy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c832a6f-e45d-46ae-8dd6-b341a479a42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2999, -0.2912,  1.1246],\n",
      "        [-0.3504, -1.1622,  0.0888]])\n"
     ]
    }
   ],
   "source": [
    "# 在指定设备 CPU或GPU上创建张量\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "d = torch.randn(2, 3, device=device)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4914740-aadc-4a0f-9e5e-343eedc8be5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b594708e-7c1a-4a2c-9d94-087174821317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e297180-4aa4-4115-b09b-84bf4c92573e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2259, -0.9172, -0.3760],\n",
       "        [ 1.0871, -0.4150,  0.3021]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.randn(2,3)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55431245-008c-4a55-a91d-dcc04270a81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2259,  1.0871],\n",
       "        [-0.9172, -0.4150],\n",
       "        [-0.3760,  0.3021]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53794237-86db-48d4-9069-2dc2ab04e546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c41609-a9ac-4aa5-abe1-1c0b9b852508",
   "metadata": {},
   "source": [
    "PyTorch的张量支持自动微分，这是深度学习中的关键特性。当你创建一个需要梯度的张量时，PyTorch可以自动计算其梯度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a41745b9-583e-4e3b-8397-cd0b7768e444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个需要梯度的张量\n",
    "tensor_requires_grad = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "tensor_result = tensor_requires_grad * 2\n",
    "tensor_result.backward()\n",
    "print(tensor_requires_grad.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b3ea2f-cb8f-41ce-b975-6bd23b008bf2",
   "metadata": {},
   "source": [
    "自动求导（Automatic Differentiation，简称Autograd）是深度学习框架中的一个核心特性，它允许计算机自动计算数学函数的导数。\n",
    "\n",
    "在深度学习中，自动求导主要用于两个方面：一是在训练神经网络时计算梯度，二是进行反向传播算法的实现。\n",
    "\n",
    "自动求导基于链式法则（Chain Rule），这是一个用于计算复杂函数导数的数学法则。链式法则表明，复合函数的导数是其各个组成部分导数的乘积。在深度学习中，模型通常是由许多层组成的复杂函数，自动求导能够高效地计算这些层的梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53a8653c-b9a1-4476-9391-7ebcef6ba3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9450,  0.0844],\n",
       "        [-0.4263, -1.4382]], requires_grad=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 2, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5f014c2-e61d-43f0-b0cb-5fbfbfeac4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.3547, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "z = y * y * 3\n",
    "out=z.mean()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11051267-1907-4e67-aa78-f828d611cde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0825, 3.1265],\n",
       "        [2.3605, 0.8428]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556eba8e-2988-4e00-b7da-b73445c41e4f",
   "metadata": {},
   "source": [
    "神经网络是一种模仿人脑神经元连接的计算模型，由多层节点（神经元）组成，用于学习数据之间的复杂模式和关系。\n",
    "\n",
    "神经网络通过调整神经元之间的连接权重来优化预测结果，这一过程涉及前向传播、损失计算、反向传播和参数更新。\n",
    "\n",
    "神经网络的类型包括前馈神经网络、卷积神经网络（CNN）、循环神经网络（RNN）和长短期记忆网络（LSTM），它们在图像识别、语音处理、自然语言处理等多个领域都有广泛应用。\n",
    "\n",
    "PyTorch 提供了一个非常方便的接口来构建神经网络模型，即 torch.nn.Module。\n",
    "\n",
    "我们可以继承 nn.Module 类并定义自己的网络层。\n",
    "\n",
    "创建一个简单的神经网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c308559-b680-4672-af50-44cfd032a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44125853-9d6f-4b59-a1f2-740a8933d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,2)\n",
    "        self.fc2 = nn.Linear(2,1)\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNN()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce749ff7-414a-4e20-8066-edc74a210d7f",
   "metadata": {},
   "source": [
    "训练过程：\n",
    "\n",
    "1.前向传播（Forward Propagation）： 在前向传播阶段，输入数据通过网络层传递，每层应用权重和激活函数，直到产生输出。\n",
    "\n",
    "2.计算损失（Calculate Loss）： 根据网络的输出和真实标签，计算损失函数的值。\n",
    "\n",
    "3.反向传播（Backpropagation）： 反向传播利用自动求导技术计算损失函数关于每个参数的梯度。\n",
    "\n",
    "4.参数更新（Parameter Update）： 使用优化器根据梯度更新网络的权重和偏置。\n",
    "\n",
    "5.迭代（Iteration）： 重复上述过程，直到模型在训练数据上的性能达到满意的水平"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61291930-385c-4190-8d39-e97c884cfcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1776]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.2018, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 随机输入\n",
    "x = torch.randn(1,2)\n",
    "\n",
    "# 前向传播\n",
    "output = model(x)\n",
    "print(output)\n",
    "\n",
    "# 定义损失函数 （例如均方误差 MSE）\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 假设目标值为1\n",
    "target = torch.randn(1, 1)\n",
    "\n",
    "# 计算损失\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5eadf11a-fc86-4963-97d5-8c80659b20b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f4ce2f-3832-43e1-b160-e7cdad258901",
   "metadata": {},
   "source": [
    "训练模型是机器学习和深度学习中的核心过程，旨在通过大量数据学习模型参数，以便模型能够对新的、未见过的数据做出准确的预测。\n",
    "\n",
    "训练模型通常包括以下几个步骤：\n",
    "\n",
    "1.数据准备：\n",
    "收集和处理数据，包括清洗、标准化和归一化。\n",
    "将数据分为训练集、验证集和测试集。\n",
    "\n",
    "2.定义模型：\n",
    "选择模型架构，例如决策树、神经网络等。\n",
    "初始化模型参数（权重和偏置）。\n",
    "\n",
    "3.选择损失函数：\n",
    "根据任务类型（如分类、回归）选择合适的损失函数。\n",
    "\n",
    "4.选择优化器：\n",
    "选择一个优化算法，如SGD、Adam等，来更新模型参数。\n",
    "\n",
    "5.前向传播：\n",
    "在每次迭代中，将输入数据通过模型传递，计算预测输出。\n",
    "\n",
    "6.计算损失：\n",
    "使用损失函数评估预测输出与真实标签之间的差异。\n",
    "\n",
    "7.反向传播：\n",
    "利用自动求导计算损失相对于模型参数的梯度。\n",
    "\n",
    "8.参数更新：\n",
    "根据计算出的梯度和优化器的策略更新模型参数。\n",
    "\n",
    "9.迭代优化：\n",
    "重复步骤5-8，直到模型在验证集上的性能不再提升或达到预定的迭代次数。\n",
    "\n",
    "10.评估和测试：\n",
    "使用测试集评估模型的最终性能，确保模型没有过拟合。\n",
    "\n",
    "11.模型调优：\n",
    "根据模型在测试集上的表现进行调参，如改变学习率、增加正则化等。\n",
    "\n",
    "\n",
    "12.部署模型：\n",
    "将训练好的模型部署到生产环境中，用于实际的预测任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5a253fd-b586-4b84-964f-b3abcf4c3a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.8937\n",
      "Epoch [20/100], Loss: 0.8722\n",
      "Epoch [30/100], Loss: 0.8510\n",
      "Epoch [40/100], Loss: 0.8301\n",
      "Epoch [50/100], Loss: 0.8097\n",
      "Epoch [60/100], Loss: 0.7900\n",
      "Epoch [70/100], Loss: 0.7708\n",
      "Epoch [80/100], Loss: 0.7525\n",
      "Epoch [90/100], Loss: 0.7349\n",
      "Epoch [100/100], Loss: 0.7182\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1.定义一个简单的神经网络\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,2)\n",
    "        self.fc2 = nn.Linear(2,1)\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 2.创建模型实例\n",
    "model = SimpleNN()\n",
    "\n",
    "#3 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#4. 假设我们有训练数据 x 和 y\n",
    "X  = torch.randn(10, 2)\n",
    "Y = torch.randn(10, 1)\n",
    "\n",
    "#5. 训练循环\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X)\n",
    "    loss = criterion(output, Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a690b1bb-fd04-416a-8fd5-10f2c27755a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
